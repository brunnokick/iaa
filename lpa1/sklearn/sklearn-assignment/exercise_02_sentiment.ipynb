{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Curso de Especialização de Inteligência Artificial Aplicada\n",
    "\n",
    "Setor de Educação Profissional e Tecnológica - SEPT\n",
    "\n",
    "Universidade Federal do Paraná - UFPR\n",
    "\n",
    "---\n",
    "\n",
    "**IAA003 - Linguagem de Programação Aplicada**\n",
    "\n",
    "Prof. Alexander Robert Kutzke\n",
    "\n",
    "# Implementação com Scikit-Learn\n",
    "\n",
    "Utilizando a base de dados presente no repositório:\n",
    "\n",
    "1. Escreva *pipeline de classificação de texto* para classificar reviews de filmes como positivos e negativos;\n",
    "2. Encontre um bom conjunto de parâmetros utilizando `GridSearchCV`;\n",
    "3. Avalie o classificador utilizando parte do conjunto de dados (previamente separado para testes).\n",
    "4. Repita os passos 1, 2 e 3 utilizando um algoritmo de classificação diferente;\n",
    "5. Escreva um pequeno texto comparando os resultados obtidos para cada algoritmo.\n",
    "\n",
    "O texto pode ser escrito em um \"Jupyter Notebook\" juntamente com o código. Ou qualquer outro tipo de documento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aluno: Brunno Cunha Mousquer de Oliveira"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Common Funcions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_train_test_data(verbose=True,\n",
    "    data_path=r\"lpa1/sklearn/sklearn-assignment/data\"):\n",
    "    movie_reviews_data_folder = data_path\n",
    "    dataset = load_files(movie_reviews_data_folder, shuffle=False)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        dataset.data, dataset.target, test_size=0.25, random_state=42)\n",
    "    if (verbose):\n",
    "        print(f\"n_samples: {len(dataset.data)}\")\n",
    "        print(f\"Train data: features: {len(x_train)} | target: {len(y_train)}\")\n",
    "        print(f\"Test data: features: {len(x_test)} | target: {len(y_test)}\")\n",
    "    return x_train, x_test, y_train, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def grid_search(model, x_train, y_train):\n",
    "    gs = GridSearchCV(model(), model.params(), n_jobs=-1, verbose=10)\n",
    "    gs = gs.fit(x_train, y_train)\n",
    "    print(f'Best score: {gs.best_score_} \\n Best Params: {gs.best_params_}')\n",
    "    # results = pd.DataFrame(gs.cv_results_()\n",
    "    return gs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def print_metrics(model, predicted, y_test):\n",
    "    print(f'Acertos: {round(np.mean(predicted == y_test) * 100,2)}%')\n",
    "    print()\n",
    "    print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "          % (model, metrics.classification_report(y_test, predicted)))\n",
    "    print()\n",
    "    print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, predicted))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class ModelBase:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.model\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        self.model.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        return self.model.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "class Model_A(ModelBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = Pipeline([\n",
    "            ('vect', CountVectorizer()),\n",
    "            ('tfidf', TfidfTransformer()),\n",
    "            ('clf', MultinomialNB())])\n",
    "\n",
    "    def params(self):\n",
    "        return {\n",
    "            'tfidf__norm': ['l1', 'l2', 'max'],\n",
    "            'tfidf__use_idf': [False, True],\n",
    "            'tfidf__smooth_idf': [False, True],\n",
    "            'tfidf__sublinear_tf': [False, True],\n",
    "            # 'clf__alpha': [v/10 for v in range(11)], não é possível usar alpha < 1.0\n",
    "            'clf__fit_prior': [False, True]\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class Model_B(ModelBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = Pipeline([\n",
    "            ('vect', CountVectorizer()),\n",
    "            ('tfidf', TfidfTransformer()),\n",
    "            ('clf', LinearSVC())])\n",
    "\n",
    "    def params(self):\n",
    "        return {\n",
    "            'tfidf__norm': ['l1', 'l2', 'max'],\n",
    "            'tfidf__use_idf': (False, True),\n",
    "            'tfidf__smooth_idf': (False, True),\n",
    "            'tfidf__sublinear_tf': (False, True),\n",
    "            'clf__penalty' : ['l1', 'l2'],\n",
    "            'clf__loss' : ['hinge', 'squared_hinge'],\n",
    "            'clf__dual': [False, True]\n",
    "            #'clf__C' : [v/10 for v in range(21) if v >= 1.0],\n",
    "            #'clf__multi_class ': ['ovr']\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "class Model_C(ModelBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = Pipeline([\n",
    "            ('vect', CountVectorizer()),\n",
    "            ('tfidf', TfidfTransformer()),\n",
    "            ('clf', DecisionTreeClassifier())])\n",
    "\n",
    "    # {'clf__criterion': 'gini', 'clf__splitter': 'best', 'tfidf__norm': 'max', 'tfidf__smooth_idf': True, 'tfidf__sublinear_tf': False, 'tfidf__use_idf': False}\n",
    "\n",
    "    def params(self):\n",
    "        return {\n",
    "            'tfidf__norm': ['max'],\n",
    "            'tfidf__use_idf': [False],\n",
    "            'tfidf__smooth_idf': [True],\n",
    "            'tfidf__sublinear_tf': [False],\n",
    "            'clf__criterion' : ['gini'],\n",
    "            'clf__splitter' : ['best'],\n",
    "            'clf__min_samples_split' : [v for v in range(50) if v >= 5],\n",
    "            'clf__min_samples_leaf' : [v for v in range(20) if v >= 5]\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RUN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "n_samples: 2000\nTrain data: features: 1500 | target: 1500\nTest data: features: 500 | target: 500\n"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = get_train_test_data(data_path=r'data/')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Acertos: 80.0%\n\nClassification report for classifier <__main__.Model_A object at 0x000001D87EF06B08>:\n              precision    recall  f1-score   support\n\n           0       0.80      0.81      0.81       257\n           1       0.80      0.79      0.79       243\n\n    accuracy                           0.80       500\n   macro avg       0.80      0.80      0.80       500\nweighted avg       0.80      0.80      0.80       500\n\n\n\nConfusion matrix:\n[[209  48]\n [ 52 191]]\n"
    }
   ],
   "source": [
    "# Default Params\n",
    "model_a = Model_A()\n",
    "model_a.fit(x_train, y_train)\n",
    "predicted = model_a.predict(x_test)\n",
    "print_metrics(model_a, predicted, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    3.4s\n[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    4.7s\n[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    7.2s\n[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    8.6s\n[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   12.1s\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   14.7s\n[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   18.6s\n[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   21.4s\n[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   26.2s\n[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   30.2s\n[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   35.4s\n[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   39.6s\n[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:   45.7s\n[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   50.9s\n[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:   57.1s\n[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.0min\n[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:  1.2min\n[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  1.3min finished\nBest score: 0.8313333333333335 \n Best Params: {'clf__fit_prior': True, 'tfidf__norm': 'max', 'tfidf__smooth_idf': False, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': False}\nAcertos: 82.2%\n\nClassification report for classifier GridSearchCV(cv=None, error_score=nan,\n             estimator=Pipeline(memory=None,\n                                steps=[('vect',\n                                        CountVectorizer(analyzer='word',\n                                                        binary=False,\n                                                        decode_error='strict',\n                                                        dtype=<class 'numpy.int64'>,\n                                                        encoding='utf-8',\n                                                        input='content',\n                                                        lowercase=True,\n                                                        max_df=1.0,\n                                                        max_features=None,\n                                                        min_df=1,\n                                                        ngram_range=(1, 1),\n                                                        preprocessor=None,\n                                                        stop_words=None,\n                                                        strip_accents=None,\n                                                        token_pattern='(...\n                                        MultinomialNB(alpha=1.0,\n                                                      class_prior=None,\n                                                      fit_prior=True))],\n                                verbose=False),\n             iid='deprecated', n_jobs=-1,\n             param_grid={'clf__fit_prior': [False, True],\n                         'tfidf__norm': ['l1', 'l2', 'max'],\n                         'tfidf__smooth_idf': [False, True],\n                         'tfidf__sublinear_tf': [False, True],\n                         'tfidf__use_idf': [False, True]},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring=None, verbose=10):\n              precision    recall  f1-score   support\n\n           0       0.83      0.82      0.83       257\n           1       0.82      0.82      0.82       243\n\n    accuracy                           0.82       500\n   macro avg       0.82      0.82      0.82       500\nweighted avg       0.82      0.82      0.82       500\n\n\n\nConfusion matrix:\n[[212  45]\n [ 44 199]]\n"
    }
   ],
   "source": [
    "# Best Features\n",
    "gs = grid_search(model_a, x_train, y_train)\n",
    "best_params_predicted = gs.predict(x_test)\n",
    "print_metrics(gs, best_params_predicted, y_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A busca por hiperametros resultou em um aumento de 2 pontos percetuais em relação ao modelo com os parametros default."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model B"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Acertos: 82.2%\n\nClassification report for classifier <__main__.Model_B object at 0x000001D86BDC6748>:\n              precision    recall  f1-score   support\n\n           0       0.83      0.82      0.83       257\n           1       0.81      0.82      0.82       243\n\n    accuracy                           0.82       500\n   macro avg       0.82      0.82      0.82       500\nweighted avg       0.82      0.82      0.82       500\n\n\n\nConfusion matrix:\n[[211  46]\n [ 43 200]]\n"
    }
   ],
   "source": [
    "# Default Params\n",
    "model_b = Model_B()\n",
    "model_b.fit(x_train, y_train)\n",
    "predicted = model_b.predict(x_test)\n",
    "print_metrics(model_b, predicted, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    3.4s\n[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    4.6s\n[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    6.6s\n[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    7.9s\n[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   11.1s\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   13.2s\n[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   16.6s\n[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   19.1s\n[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   23.1s\n[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   26.4s\n[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   30.7s\n[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   34.6s\n[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:   39.1s\n[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   43.6s\n[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:   48.4s\n[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   53.4s\n[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:   59.0s\n[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:  1.1min\n[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:  1.2min\n[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.3min\n[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed:  1.5min\n[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:  1.7min\n[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  1.9min\n[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:  2.1min\n[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed:  2.2min\n[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.4min\n[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed:  2.7min\n[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:  2.8min\n[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed:  3.0min\n[Parallel(n_jobs=-1)]: Done 570 tasks      | elapsed:  3.2min\n[Parallel(n_jobs=-1)]: Done 605 tasks      | elapsed:  3.3min\n[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  3.5min\n[Parallel(n_jobs=-1)]: Done 677 tasks      | elapsed:  3.8min\n[Parallel(n_jobs=-1)]: Done 714 tasks      | elapsed:  4.0min\n[Parallel(n_jobs=-1)]: Done 753 tasks      | elapsed:  4.2min\n[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  4.4min\n[Parallel(n_jobs=-1)]: Done 833 tasks      | elapsed:  4.6min\n[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  4.8min\n[Parallel(n_jobs=-1)]: Done 917 tasks      | elapsed:  5.0min\n[Parallel(n_jobs=-1)]: Done 960 out of 960 | elapsed:  5.3min finished\nBest score: 0.8726666666666667 \n Best Params: {'clf__dual': True, 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'tfidf__norm': 'l2', 'tfidf__smooth_idf': True, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\nAcertos: 84.6%\n\nClassification report for classifier GridSearchCV(cv=None, error_score=nan,\n             estimator=Pipeline(memory=None,\n                                steps=[('vect',\n                                        CountVectorizer(analyzer='word',\n                                                        binary=False,\n                                                        decode_error='strict',\n                                                        dtype=<class 'numpy.int64'>,\n                                                        encoding='utf-8',\n                                                        input='content',\n                                                        lowercase=True,\n                                                        max_df=1.0,\n                                                        max_features=None,\n                                                        min_df=1,\n                                                        ngram_range=(1, 1),\n                                                        preprocessor=None,\n                                                        stop_words=None,\n                                                        strip_accents=None,\n                                                        token_pattern='(...\n                                verbose=False),\n             iid='deprecated', n_jobs=-1,\n             param_grid={'clf__dual': [False, True],\n                         'clf__loss': ['hinge', 'squared_hinge'],\n                         'clf__penalty': ['l1', 'l2'],\n                         'tfidf__norm': ['l1', 'l2', 'max'],\n                         'tfidf__smooth_idf': (False, True),\n                         'tfidf__sublinear_tf': (False, True),\n                         'tfidf__use_idf': (False, True)},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring=None, verbose=10):\n              precision    recall  f1-score   support\n\n           0       0.85      0.85      0.85       257\n           1       0.84      0.84      0.84       243\n\n    accuracy                           0.85       500\n   macro avg       0.85      0.85      0.85       500\nweighted avg       0.85      0.85      0.85       500\n\n\n\nConfusion matrix:\n[[218  39]\n [ 38 205]]\n"
    }
   ],
   "source": [
    "# Predict with best features\n",
    "gs = grid_search(model_b, x_train, y_train)\n",
    "best_params_predicted = gs.predict(x_test)\n",
    "print_metrics(gs, best_params_predicted, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### O modelo B com parametros default possui a mesma quantidade de acertos que o modelo A com hiperparametros. O modelo B utiliza o algoritmos LinearSVC como classificador, enquanto o modelo A  tiliza o MultinomialNB.\n",
    "\n",
    "#### Ao realizar a bysca por hiperparametros, chegamos em 84.6% de acertos"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Modelo C"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Acertos: 65.4%\n\nClassification report for classifier <__main__.Model_C object at 0x000001D804210608>:\n              precision    recall  f1-score   support\n\n           0       0.66      0.67      0.66       257\n           1       0.64      0.64      0.64       243\n\n    accuracy                           0.65       500\n   macro avg       0.65      0.65      0.65       500\nweighted avg       0.65      0.65      0.65       500\n\n\n\nConfusion matrix:\n[[171  86]\n [ 87 156]]\n"
    }
   ],
   "source": [
    "# Default Params\n",
    "model_c = Model_C()\n",
    "model_c.fit(x_train, y_train)\n",
    "predicted = model_c.predict(x_test)\n",
    "print_metrics(model_c, predicted, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 5 folds for each of 675 candidates, totalling 3375 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    4.1s\n[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    6.3s\n[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   10.5s\n[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   12.9s\n[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   19.1s\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   23.3s\n[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   29.5s\n[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   34.2s\n[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   42.4s\n[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   48.7s\n[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   57.1s\n[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  1.1min\n[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:  1.2min\n[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.4min\n[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:  1.6min\n[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.7min\n[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:  1.9min\n[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:  2.1min\n[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:  2.3min\n[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  2.5min\n[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed:  2.7min\n[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:  3.0min\n[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  3.2min\n[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:  3.4min\n[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed:  3.7min\n[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  3.9min\n[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed:  4.2min\n[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:  4.4min\n[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed:  4.7min\n[Parallel(n_jobs=-1)]: Done 570 tasks      | elapsed:  5.0min\n[Parallel(n_jobs=-1)]: Done 605 tasks      | elapsed:  5.3min\n[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  5.6min\n[Parallel(n_jobs=-1)]: Done 677 tasks      | elapsed:  5.9min\n[Parallel(n_jobs=-1)]: Done 714 tasks      | elapsed:  6.2min\n[Parallel(n_jobs=-1)]: Done 753 tasks      | elapsed:  6.5min\n[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  6.8min\n[Parallel(n_jobs=-1)]: Done 833 tasks      | elapsed:  7.2min\n[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  7.5min\n[Parallel(n_jobs=-1)]: Done 917 tasks      | elapsed:  7.9min\n[Parallel(n_jobs=-1)]: Done 960 tasks      | elapsed:  8.2min\n[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  8.6min\n[Parallel(n_jobs=-1)]: Done 1050 tasks      | elapsed:  9.0min\n[Parallel(n_jobs=-1)]: Done 1097 tasks      | elapsed:  9.3min\n[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed:  9.7min\n[Parallel(n_jobs=-1)]: Done 1193 tasks      | elapsed: 10.1min\n[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 10.5min\n[Parallel(n_jobs=-1)]: Done 1293 tasks      | elapsed: 10.9min\n[Parallel(n_jobs=-1)]: Done 1344 tasks      | elapsed: 11.3min\n[Parallel(n_jobs=-1)]: Done 1397 tasks      | elapsed: 11.7min\n[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed: 12.2min\n[Parallel(n_jobs=-1)]: Done 1505 tasks      | elapsed: 12.6min\n[Parallel(n_jobs=-1)]: Done 1560 tasks      | elapsed: 13.1min\n[Parallel(n_jobs=-1)]: Done 1617 tasks      | elapsed: 13.6min\n[Parallel(n_jobs=-1)]: Done 1674 tasks      | elapsed: 14.0min\n[Parallel(n_jobs=-1)]: Done 1733 tasks      | elapsed: 14.5min\n[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 14.9min\n[Parallel(n_jobs=-1)]: Done 1853 tasks      | elapsed: 15.4min\n[Parallel(n_jobs=-1)]: Done 1914 tasks      | elapsed: 15.9min\n[Parallel(n_jobs=-1)]: Done 1977 tasks      | elapsed: 16.4min\n[Parallel(n_jobs=-1)]: Done 2040 tasks      | elapsed: 16.9min\n[Parallel(n_jobs=-1)]: Done 2105 tasks      | elapsed: 17.4min\n[Parallel(n_jobs=-1)]: Done 2170 tasks      | elapsed: 17.9min\n[Parallel(n_jobs=-1)]: Done 2237 tasks      | elapsed: 18.4min\n[Parallel(n_jobs=-1)]: Done 2304 tasks      | elapsed: 18.9min\n[Parallel(n_jobs=-1)]: Done 2373 tasks      | elapsed: 19.4min\n[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed: 19.9min\n[Parallel(n_jobs=-1)]: Done 2513 tasks      | elapsed: 20.5min\n[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 21.0min\n[Parallel(n_jobs=-1)]: Done 2657 tasks      | elapsed: 21.6min\n[Parallel(n_jobs=-1)]: Done 2730 tasks      | elapsed: 22.1min\n[Parallel(n_jobs=-1)]: Done 2805 tasks      | elapsed: 22.7min\n[Parallel(n_jobs=-1)]: Done 2880 tasks      | elapsed: 23.3min\n[Parallel(n_jobs=-1)]: Done 2957 tasks      | elapsed: 23.9min\n[Parallel(n_jobs=-1)]: Done 3034 tasks      | elapsed: 24.4min\n[Parallel(n_jobs=-1)]: Done 3113 tasks      | elapsed: 25.0min\n[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed: 25.6min\n[Parallel(n_jobs=-1)]: Done 3273 tasks      | elapsed: 26.2min\n[Parallel(n_jobs=-1)]: Done 3354 tasks      | elapsed: 26.8min\n[Parallel(n_jobs=-1)]: Done 3375 out of 3375 | elapsed: 27.0min finished\nBest score: 0.6766666666666666 \n Best Params: {'clf__criterion': 'gini', 'clf__min_samples_leaf': 7, 'clf__min_samples_split': 38, 'clf__splitter': 'best', 'tfidf__norm': 'max', 'tfidf__smooth_idf': True, 'tfidf__sublinear_tf': False, 'tfidf__use_idf': False}\nAcertos: 62.8%\n\nClassification report for classifier GridSearchCV(cv=None, error_score=nan,\n             estimator=Pipeline(memory=None,\n                                steps=[('vect',\n                                        CountVectorizer(analyzer='word',\n                                                        binary=False,\n                                                        decode_error='strict',\n                                                        dtype=<class 'numpy.int64'>,\n                                                        encoding='utf-8',\n                                                        input='content',\n                                                        lowercase=True,\n                                                        max_df=1.0,\n                                                        max_features=None,\n                                                        min_df=1,\n                                                        ngram_range=(1, 1),\n                                                        preprocessor=None,\n                                                        stop_words=None,\n                                                        strip_accents=None,\n                                                        token_pattern='(...\n                                                   13, 14, 15, 16, 17, 18, 19],\n                         'clf__min_samples_split': [5, 6, 7, 8, 9, 10, 11, 12,\n                                                    13, 14, 15, 16, 17, 18, 19,\n                                                    20, 21, 22, 23, 24, 25, 26,\n                                                    27, 28, 29, 30, 31, 32, 33,\n                                                    34, ...],\n                         'clf__splitter': ['best'], 'tfidf__norm': ['max'],\n                         'tfidf__smooth_idf': [True],\n                         'tfidf__sublinear_tf': [False],\n                         'tfidf__use_idf': [False]},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring=None, verbose=10):\n              precision    recall  f1-score   support\n\n           0       0.64      0.63      0.63       257\n           1       0.61      0.63      0.62       243\n\n    accuracy                           0.63       500\n   macro avg       0.63      0.63      0.63       500\nweighted avg       0.63      0.63      0.63       500\n\n\n\nConfusion matrix:\n[[161  96]\n [ 90 153]]\n"
    }
   ],
   "source": [
    "# Predict with best features\n",
    "gs = grid_search(model_c, x_train, y_train)\n",
    "best_params_predicted = gs.predict(x_test)\n",
    "print_metrics(gs, best_params_predicted, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### O modelo C teve a pior performance entre os 3, mesmo com busca por hiperparametros não consegui chegar nos 80%. Um problema que identifiquei foi que a busca por hiperparametros escala no processamento devido aos parametros inteiros da arvore. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-2747dce9",
   "language": "python",
   "display_name": "PyCharm (iaa)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
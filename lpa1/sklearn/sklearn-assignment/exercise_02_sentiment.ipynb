{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Curso de Especialização de Inteligência Artificial Aplicada\n",
    "\n",
    "Setor de Educação Profissional e Tecnológica - SEPT\n",
    "\n",
    "Universidade Federal do Paraná - UFPR\n",
    "\n",
    "---\n",
    "\n",
    "**IAA003 - Linguagem de Programação Aplicada**\n",
    "\n",
    "Prof. Alexander Robert Kutzke\n",
    "\n",
    "# Implementação com Scikit-Learn\n",
    "\n",
    "Utilizando a base de dados presente no repositório:\n",
    "\n",
    "1. Escreva *pipeline de classificação de texto* para classificar reviews de filmes como positivos e negativos;\n",
    "2. Encontre um bom conjunto de parâmetros utilizando `GridSearchCV`;\n",
    "3. Avalie o classificador utilizando parte do conjunto de dados (previamente separado para testes).\n",
    "4. Repita os passos 1, 2 e 3 utilizando um algoritmo de classificação diferente;\n",
    "5. Escreva um pequeno texto comparando os resultados obtidos para cada algoritmo.\n",
    "\n",
    "O texto pode ser escrito em um \"Jupyter Notebook\" juntamente com o código. Ou qualquer outro tipo de documento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aluno: Brunno Cunha Mousquer de Oliveira"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Common Funcions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def get_train_test_data(verbose=True,\n",
    "    data_path=r\"lpa1/sklearn/sklearn-assignment/data\"):\n",
    "    movie_reviews_data_folder = data_path\n",
    "    dataset = load_files(movie_reviews_data_folder, shuffle=False)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        dataset.data, dataset.target, test_size=0.25, random_state=42)\n",
    "    if (verbose):\n",
    "        print(f\"n_samples: {len(dataset.data)}\")\n",
    "        print(f\"Train data: features: {len(x_train)} | target: {len(y_train)}\")\n",
    "        print(f\"Test data: features: {len(x_test)} | target: {len(y_test)}\")\n",
    "    return x_train, x_test, y_train, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def grid_search(model, x_train, y_train):\n",
    "    gs = GridSearchCV(model(), model.params(), n_jobs=-1, verbose=10)\n",
    "    gs = gs.fit(x_train, y_train)\n",
    "    print(f'Best score: {gs.best_score_} \\n Best Params: {gs.best_params_}')\n",
    "    # results = pd.DataFrame(gs.cv_results_()\n",
    "    return gs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def print_metrics(model, predicted, y_test):\n",
    "    print(f'Acertos: {round(np.mean(predicted == y_test) * 100,2)}%')\n",
    "    print()\n",
    "    print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "          % (model, metrics.classification_report(y_test, predicted)))\n",
    "    print()\n",
    "    print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, predicted))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class ModelBase:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.model\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        self.model.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        return self.model.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "class Model_A(ModelBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = Pipeline([\n",
    "            ('vect', CountVectorizer()),\n",
    "            ('tfidf', TfidfTransformer()),\n",
    "            ('clf', MultinomialNB())])\n",
    "\n",
    "    def params(self):\n",
    "        return {\n",
    "            'tfidf__norm': ['l1', 'l2', 'max'],\n",
    "            'tfidf__use_idf': [False, True],\n",
    "            'tfidf__smooth_idf': [False, True],\n",
    "            'tfidf__sublinear_tf': [False, True],\n",
    "            # 'clf__alpha': [v/10 for v in range(11)], não é possível usar alpha < 1.0\n",
    "            'clf__fit_prior': [False, True]\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "class Model_B(ModelBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = Pipeline([\n",
    "            ('vect', CountVectorizer()),\n",
    "            ('tfidf', TfidfTransformer()),\n",
    "            ('clf', LinearSVC())])\n",
    "\n",
    "    def params(self):\n",
    "        return {\n",
    "            'tfidf__norm': ['l1', 'l2', 'max'],\n",
    "            'tfidf__use_idf': (False, True),\n",
    "            'tfidf__smooth_idf': (False, True),\n",
    "            'tfidf__sublinear_tf': (False, True),\n",
    "            'clf__penalty' : ['l1', 'l2'],\n",
    "            'clf__loss' : ['hinge', 'squared_hinge'],\n",
    "            'clf__dual': [False, True]\n",
    "            #'clf__C' : [v/10 for v in range(21) if v >= 1.0],\n",
    "            #'clf__multi_class ': ['ovr']\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "class Model_C(ModelBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = Pipeline([\n",
    "            ('vect', CountVectorizer()),\n",
    "            ('tfidf', TfidfTransformer()),\n",
    "            ('clf', DecisionTreeClassifier())])\n",
    "\n",
    "    def params(self):\n",
    "        return {\n",
    "            'tfidf__norm': ['l1', 'l2', 'max'],\n",
    "            'tfidf__use_idf': [False, True],\n",
    "            'tfidf__smooth_idf': [False, True],\n",
    "            'tfidf__sublinear_tf': [False, True],\n",
    "            'clf__criterion' : ['gini', 'entropy'],\n",
    "            'clf__splitter' : ['best', 'random'],\n",
    "            'clf__min_samples_split' : [v for v in range(100) if v >= 5],\n",
    "            'clf__min_samples_leaf' : [v for v in range(20) if v >= 5]\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RUN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 2000\n",
      "Train data: features: 1500 | target: 1500\n",
      "Test data: features: 500 | target: 500\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = get_train_test_data(data_path=r'data/')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model A"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acertos: 80.0%\n",
      "\n",
      "Classification report for classifier <__main__.Model_A object at 0x000001A089D17B48>:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81       257\n",
      "           1       0.80      0.79      0.79       243\n",
      "\n",
      "    accuracy                           0.80       500\n",
      "   macro avg       0.80      0.80      0.80       500\n",
      "weighted avg       0.80      0.80      0.80       500\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[209  48]\n",
      " [ 52 191]]\n"
     ]
    }
   ],
   "source": [
    "# Default Params\n",
    "model_a = Model_A()\n",
    "model_a.fit(x_train, y_train)\n",
    "predicted = model_a.predict(x_test)\n",
    "print_metrics(model_a, predicted, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Best score: 0.8313333333333335 \n",
      " Best Params: {'clf__fit_prior': True, 'tfidf__norm': 'max', 'tfidf__smooth_idf': False, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': False}\n",
      "Acertos: 82.2%\n",
      "\n",
      "Classification report for classifier GridSearchCV(cv=None, error_score=nan,\n",
      "             estimator=Pipeline(memory=None,\n",
      "                                steps=[('vect',\n",
      "                                        CountVectorizer(analyzer='word',\n",
      "                                                        binary=False,\n",
      "                                                        decode_error='strict',\n",
      "                                                        dtype=<class 'numpy.int64'>,\n",
      "                                                        encoding='utf-8',\n",
      "                                                        input='content',\n",
      "                                                        lowercase=True,\n",
      "                                                        max_df=1.0,\n",
      "                                                        max_features=None,\n",
      "                                                        min_df=1,\n",
      "                                                        ngram_range=(1, 1),\n",
      "                                                        preprocessor=None,\n",
      "                                                        stop_words=None,\n",
      "                                                        strip_accents=None,\n",
      "                                                        token_pattern='(...\n",
      "                                        MultinomialNB(alpha=1.0,\n",
      "                                                      class_prior=None,\n",
      "                                                      fit_prior=True))],\n",
      "                                verbose=False),\n",
      "             iid='deprecated', n_jobs=-1,\n",
      "             param_grid={'clf__fit_prior': [False, True],\n",
      "                         'tfidf__norm': ['l1', 'l2', 'max'],\n",
      "                         'tfidf__smooth_idf': [False, True],\n",
      "                         'tfidf__sublinear_tf': [False, True],\n",
      "                         'tfidf__use_idf': [False, True]},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=10):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83       257\n",
      "           1       0.82      0.82      0.82       243\n",
      "\n",
      "    accuracy                           0.82       500\n",
      "   macro avg       0.82      0.82      0.82       500\n",
      "weighted avg       0.82      0.82      0.82       500\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[212  45]\n",
      " [ 44 199]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   25.3s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   33.3s\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:   38.2s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   42.7s\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:   47.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   52.7s\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:   58.5s\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "# Best Features\n",
    "gs = grid_search(model_a, x_train, y_train)\n",
    "best_params_predicted = gs.predict(x_test)\n",
    "print_metrics(gs, best_params_predicted, y_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A busca por hiperametros resultou em um aumento de 2 pontos percetuais em relação ao modelo\n",
    "com os parametros default."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model B"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acertos: 82.2%\n",
      "\n",
      "Classification report for classifier <__main__.Model_B object at 0x000001A08FC63A48>:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83       257\n",
      "           1       0.81      0.82      0.82       243\n",
      "\n",
      "    accuracy                           0.82       500\n",
      "   macro avg       0.82      0.82      0.82       500\n",
      "weighted avg       0.82      0.82      0.82       500\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[211  46]\n",
      " [ 43 200]]\n"
     ]
    }
   ],
   "source": [
    "# Default Params\n",
    "model_b = Model_B()\n",
    "model_b.fit(x_train, y_train)\n",
    "predicted = model_b.predict(x_test)\n",
    "print_metrics(model_b, predicted, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n",
      "Best score: 0.8726666666666667 \n",
      " Best Params: {'clf__dual': True, 'clf__loss': 'hinge', 'clf__penalty': 'l2', 'tfidf__norm': 'l2', 'tfidf__smooth_idf': True, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Acertos: 84.6%\n",
      "\n",
      "Classification report for classifier GridSearchCV(cv=None, error_score=nan,\n",
      "             estimator=Pipeline(memory=None,\n",
      "                                steps=[('vect',\n",
      "                                        CountVectorizer(analyzer='word',\n",
      "                                                        binary=False,\n",
      "                                                        decode_error='strict',\n",
      "                                                        dtype=<class 'numpy.int64'>,\n",
      "                                                        encoding='utf-8',\n",
      "                                                        input='content',\n",
      "                                                        lowercase=True,\n",
      "                                                        max_df=1.0,\n",
      "                                                        max_features=None,\n",
      "                                                        min_df=1,\n",
      "                                                        ngram_range=(1, 1),\n",
      "                                                        preprocessor=None,\n",
      "                                                        stop_words=None,\n",
      "                                                        strip_accents=None,\n",
      "                                                        token_pattern='(...\n",
      "                                verbose=False),\n",
      "             iid='deprecated', n_jobs=-1,\n",
      "             param_grid={'clf__dual': [False, True],\n",
      "                         'clf__loss': ['hinge', 'squared_hinge'],\n",
      "                         'clf__penalty': ['l1', 'l2'],\n",
      "                         'tfidf__norm': ['l1', 'l2', 'max'],\n",
      "                         'tfidf__smooth_idf': (False, True),\n",
      "                         'tfidf__sublinear_tf': (False, True),\n",
      "                         'tfidf__use_idf': (False, True)},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=10):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85       257\n",
      "           1       0.84      0.84      0.84       243\n",
      "\n",
      "    accuracy                           0.85       500\n",
      "   macro avg       0.85      0.85      0.85       500\n",
      "weighted avg       0.85      0.85      0.85       500\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[218  39]\n",
      " [ 38 205]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   27.3s\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   35.3s\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   43.7s\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:   48.6s\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:   53.4s\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 570 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 605 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 677 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 714 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 753 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 833 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 917 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 960 out of 960 | elapsed:  4.4min finished\n"
     ]
    }
   ],
   "source": [
    "# Predict with best features\n",
    "gs = grid_search(model_b, x_train, y_train)\n",
    "best_params_predicted = gs.predict(x_test)\n",
    "print_metrics(gs, best_params_predicted, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "O modelo B com parametros default possui a mesma quantidade de acertos que o modelo A com hiperparametros.\n",
    "O modelo B utiliza o algoritmos LinearSVC como classificador, enquanto o modelo A utiliza o MultinomialNB.\n",
    "\n",
    "Ao realizar a bysca por hiperparametros, chegamos em 84.6% de acertos"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Modelo C"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acertos: 64.8%\n",
      "\n",
      "Classification report for classifier <__main__.Model_C object at 0x000001A08A0F8A88>:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.67      0.66       257\n",
      "           1       0.64      0.62      0.63       243\n",
      "\n",
      "    accuracy                           0.65       500\n",
      "   macro avg       0.65      0.65      0.65       500\n",
      "weighted avg       0.65      0.65      0.65       500\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[173  84]\n",
      " [ 92 151]]\n"
     ]
    }
   ],
   "source": [
    "# Default Params\n",
    "model_c = Model_C()\n",
    "model_c.fit(x_train, y_train)\n",
    "predicted = model_c.predict(x_test)\n",
    "print_metrics(model_c, predicted, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "Best score: 0.6719999999999999 \n",
      " Best Params: {'clf__criterion': 'gini', 'clf__splitter': 'best', 'tfidf__norm': 'max', 'tfidf__smooth_idf': False, 'tfidf__sublinear_tf': False, 'tfidf__use_idf': False}\n",
      "Acertos: 60.4%\n",
      "\n",
      "Classification report for classifier GridSearchCV(cv=None, error_score=nan,\n",
      "             estimator=Pipeline(memory=None,\n",
      "                                steps=[('vect',\n",
      "                                        CountVectorizer(analyzer='word',\n",
      "                                                        binary=False,\n",
      "                                                        decode_error='strict',\n",
      "                                                        dtype=<class 'numpy.int64'>,\n",
      "                                                        encoding='utf-8',\n",
      "                                                        input='content',\n",
      "                                                        lowercase=True,\n",
      "                                                        max_df=1.0,\n",
      "                                                        max_features=None,\n",
      "                                                        min_df=1,\n",
      "                                                        ngram_range=(1, 1),\n",
      "                                                        preprocessor=None,\n",
      "                                                        stop_words=None,\n",
      "                                                        strip_accents=None,\n",
      "                                                        token_pattern='(...\n",
      "                                                               splitter='best'))],\n",
      "                                verbose=False),\n",
      "             iid='deprecated', n_jobs=-1,\n",
      "             param_grid={'clf__criterion': ['gini', 'entropy'],\n",
      "                         'clf__splitter': ['best', 'random'],\n",
      "                         'tfidf__norm': ['l1', 'l2', 'max'],\n",
      "                         'tfidf__smooth_idf': [False, True],\n",
      "                         'tfidf__sublinear_tf': [False, True],\n",
      "                         'tfidf__use_idf': [False, True]},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=10):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.61      0.61       257\n",
      "           1       0.59      0.60      0.59       243\n",
      "\n",
      "    accuracy                           0.60       500\n",
      "   macro avg       0.60      0.60      0.60       500\n",
      "weighted avg       0.60      0.60      0.60       500\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[157 100]\n",
      " [ 98 145]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   23.4s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   33.9s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   41.8s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   49.5s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   58.7s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed:  4.1min finished\n"
     ]
    }
   ],
   "source": [
    "# Predict with best features\n",
    "gs = grid_search(model_c, x_train, y_train)\n",
    "best_params_predicted = gs.predict(x_test)\n",
    "print_metrics(gs, best_params_predicted, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "O modelo C teve a pior performance entre os 3, talvez arvores de decicoes não sejam uma boa opcao\n",
    "para classificao de valores.\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-2747dce9",
   "language": "python",
   "display_name": "PyCharm (iaa)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}